#Used by networks to plot the confusion matrix
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import itertools

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
  """
  This function prints and plots the confusion matrix.
  Normalization can be applied by setting `normalize=True`.
  """
  if normalize:
      cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
      print("Normalized confusion matrix")
  else:
      print('Confusion matrix, without normalization')

  print(cm)

  plt.imshow(cm, interpolation='nearest', cmap=cmap)
  plt.title(title)
  plt.colorbar()
  tick_marks = np.arange(len(classes))
  plt.xticks(tick_marks, classes, rotation=45)
  plt.yticks(tick_marks, classes)

  fmt = '.2f' if normalize else 'd'
  thresh = cm.max() / 2.
  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
      plt.text(j, i, format(cm[i, j], fmt),
               horizontalalignment="center",
               color="white" if cm[i, j] > thresh else "black")

  plt.tight_layout()
  plt.ylabel('True label')
  plt.xlabel('Predicted label')
  plt.show()


if __name__ == '__main__':
    #Example
    ldp_loss = [0.8944912552833557, 0.4804067015647888, 0.41378656029701233, 0.30051687359809875, 0.336376816034317, 0.289985328912735, 0.3259170651435852, 
    0.24942807853221893, 0.22875681519508362, 0.2430097907781601, 0.19033364951610565, 0.19278086721897125, 0.24264350533485413, 0.23196841776371002, 0.2478194683790207,
    0.2004265934228897, 0.19122330844402313, 0.15994352102279663, 0.1328279823064804, 0.14690625667572021, 0.13964961469173431, 0.13564178347587585, 
    0.13026933372020721, 0.16308729350566864, 0.11329271644353867] 
    ldp_val_loss = [0.465213805437088, 1.044731616973877, 1.0150964260101318, 1.092516541481018, 0.3696190118789673, 0.8996700644493103, 0.6090677976608276, 
    3.2594451904296875, 1.0272506475448608, 0.823196530342102, 0.4841877520084381, 0.4844660758972168, 1.9400157928466797, 0.8848426342010498, 0.6121761798858643, 
    0.4367879033088684, 0.4597920775413513, 0.476722776889801, 1.4831082820892334, 0.33267641067504883, 1.8023840188980103, 0.6160886883735657, 
    0.8558369874954224, 0.7243109345436096, 0.8133922219276428]

    ldp_acc = [0.7268170714378357, 0.8280701637268066, 0.8516290783882141, 0.8889724016189575, 0.8819549083709717, 0.8999999761581421, 0.8914787173271179, 
    0.9115288257598877, 0.9197995066642761, 0.9243108034133911, 0.9355889558792114, 0.9360902309417725, 0.9288220405578613, 0.9225564002990723, 0.9210526347160339, 
    0.931829571723938, 0.942606508731842, 0.9448621273040771, 0.9563909769058228, 0.9546365737915039, 0.9538847208023071, 0.9561403393745422, 
    0.9558897018432617, 0.947117805480957, 0.961403489112854]
    ldp_val_acc = [0.7757322192192078, 0.6836820244789124, 0.6769874691963196, 0.6861924529075623, 0.866108775138855, 0.7807531356811523, 0.7497907876968384, 
    0.6485355496406555, 0.7983263731002808, 0.7740585803985596, 0.8418409824371338, 0.849372386932373, 0.6309623718261719, 0.7899581789970398, 0.8652719855308533, 
    0.866108775138855, 0.8594142198562622, 0.8326359987258911, 0.7640167474746704, 0.866108775138855, 0.8267782330513, 0.8426778316497803, 
    0.7991631627082825, 0.8158996105194092, 0.8217573165893555]

    plt.plot(ldp_loss, label='loss')
    plt.plot(ldp_val_loss, label='val_loss')
    plt.legend()

    plt.show()

    plt.plot(ldp_acc, label='acc')
    plt.plot(ldp_val_acc, label='val_acc')
    plt.legend()

    plt.show()